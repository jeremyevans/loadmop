#!/usr/bin/env ruby

require 'bundler'
Bundler.setup
Bundler.require(:default)

require 'pathname'
require 'csv'

class LoadMOPCli < Thor
  include Sequelizer
  desc 'load_vocab_tables', 'Connects to database specified in the .env file and loads the OMOP Vocabulary schema'
  def load_vocab_tables
    Sequel.extension :migration
    Sequel::Migrator.run(db, 'schemas/vocabulary', target: 1)
  end

  desc 'load_vocab_data vocab_file_path', 'Connects to database specified in the .env file and loads the OMOP Vocabulary schema and data into it'
  def load_vocab_data(file_path)
    load_vocab_tables
    fix_vocab_data(file_path)
    fast_load(file_path) || slow_load(file_path)
  end

  desc 'fix_data file_path', 'The vocab files come with a \'|\' character appended to each line, so we clean this off'
  def fix_vocab_data(file_path)
    Pathname.glob(file_path + '/*.csv') do |vocab_file|
      clean_dir = vocab_file.dirname + 'cleaned'
      clean_dir.mkdir unless clean_dir.exist?
      clean_file = clean_dir + vocab_file.basename
      next if clean_file.exist?
      puts "Cleaning #{vocab_file}"
      system("head -n 1 #{vocab_file} | sed 's/\|$//' | tr '[A-Z]' '[a-z]' >> #{clean_file}")
      system("tail -n +2 #{vocab_file} | sed 's/\|$//' >> #{clean_file}")
    end
  end

  desc 'load_vocab_indexes', 'Loads some indexes into the vocabulary database.  Wait until data is already loaded'
  def load_vocab_indexes
    Sequel.extension :migration
    Sequel::Migrator.run(db, 'schemas/vocabulary', target: 2)
  end

  desc 'test_vocab', 'Makes sure conncetion works'
  def test_vocab
    puts db[:vocabulary].count
  end

  private

  def fast_load(file_path)
    case adapter
    when 'postgres'
      fast_load_postgres(file_path)
    when 'sqlite'
      fast_load_sqlite(file_path)
    else
      nil
    end
  end

=begin
This wasn't so fast...
  def super_fast_load_postgres(file_path)
    return false if `which pgloader` =~ /not found/i
    Pathname.glob(Pathname.new(file_path) + 'cleaned' + '*.csv') do |vocab_file|
      table_name = vocab_file.basename('.*').to_s.downcase.to_sym
      puts "Loading #{vocab_file} into #{table_name}"
      File.open('/tmp/pg.load', 'w') do |file|
        file.puts <<-EOF
LOAD CSV
FROM #{vocab_file} WITH ENCODING LATIN-1
INTO #{db_url}?#{ENV['DB_SEARCH_PATH']}.#{table_name}
WITH truncate,
     fields terminated by ',',
     skip header = 1
;
EOF
      end
      system('pgloader -v /tmp/pg.load')
    end
    true
  end
=end

  def fast_load_postgres(file_path)
    Pathname.glob(Pathname.new(file_path) + 'cleaned' + '*.csv') do |vocab_file|
      table_name = vocab_file.basename('.*').to_s.downcase.to_sym
      puts "Loading #{vocab_file} into #{table_name}"
      headers = headers_for(vocab_file).map(&:to_sym)
      db[table_name].truncate
      db.copy_into(
        table_name,
        format:  :csv,
        columns: headers,
        options: 'header',
        data:    File.read(vocab_file)
      )
    end
    true
  end

  def fast_load_sqlite(file_path)
    return nil if `which sqlite3` =~ /not found/i
    db_file_path = database
    Pathname.glob(Pathname.new(file_path) + 'cleaned' + '*.csv') do |vocab_file|
      File.open('/tmp/sqlite.load', 'w') do |file|
        table_name = vocab_file.basename('.*').to_s.downcase
        puts "Loading #{vocab_file} into #{table_name}"
        file.puts %Q(.echo on)
        file.puts %Q(.log stdout)
        file.puts %Q(DELETE FROM #{table_name};)
        file.puts %Q(.mode csv)
        file.puts ".import /dev/stdin #{table_name}"
      end
      command = "tail -n +2 #{vocab_file} | sqlite3 #{db_file_path} '.read /tmp/sqlite.load'"
      puts command
      system(command)
    end
    true
  end

  def slow_load(file_path)
    Pathname.glob(Pathname.new(file_path) + 'cleaned' + '*.csv') do |vocab_file|
      table_name = vocab_file.basename('.*').to_s.downcase.to_sym
      puts "Loading #{vocab_file} into #{table_name}"
      CSV.open(vocab_file, headers: true) do |csv|
        csv.each_slice(1000) do |rows|
          print '.'
          db[table_name].import(headers_for(vocab_file), rows.map(&:fields))
        end
      end
      puts
    end
  end

  def adapter
    db.sequelizer_options['adapter']
  end

  def database
    db.sequelizer_options['database']
  end

  def headers_for(file_path)
    header_line = File.readlines(file_path).first.downcase
    CSV.parse(header_line).first
  end
end

LoadMOPCli.start(ARGV)
